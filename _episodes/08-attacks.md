---
title: "Susceptibility"
teaching: 20
exercises: 10
questions:
- "How can models be intentionally mislead?"
objectives:
- "Understand the concept of adversarial attacks."
keypoints:
- "Models are susceptible to manipulation."
---

## Manipulation of models

It is important to be aware that models are susceptible to manipulation by targeted attacks. While the risk of attack is limited in most cases of model deployment, it is reasonable to assume that the risk will increase as the stakes increase. A model is susceptible to attack if it can be manipulated to produce an unexpected output.



https://twitter.com/MIT_CSAIL/status/1507754751995260931

https://slate.com/technology/2018/01/google-researchers-tricked-an-a-i-into-thinking-a-banana-was-a-toaster.html

https://www.theguardian.com/technology/2021/mar/08/typographic-attack-pen-paper-fool-ai-thinking-apple-ipod-clip


https://kde.mitre.org/blog/2018/10/28/is-this-a-wolf-understanding-bias-in-machine-learning/

https://arxiv.org/abs/1804.05296


<!--  TODO:

Look at 4 in https://arxiv.org/pdf/2012.05345.pdf



-->

## Data injection

<!--  TODO:

Where models are continuously trained, there is risk that new training data might be intentionally injected in order to achieve a desired outcome.

-->

## Adversarial attacks

<!--  TODO:

Data can be overlaid with targeted values that lead to misclassification.

https://www.science.org/doi/10.1126/science.aaw4399

https://arxiv.org/abs/1804.05296

Examples, and discussion.

-->

{% include links.md %}